# âœˆï¸ Airport Enquiry Bot

An AI-powered chatbot that answers user queries about Changi Airport using Retrieval-Augmented Generation (RAG). This project integrates a FastAPI backend and a Streamlit frontend for both API and user-friendly interface support.

---



---

## ğŸ“ Project Structure

```
airport-enquiry-bot/
                      
â”œâ”€â”€ chatbot/
â”‚   â”œâ”€â”€ app.py                 # FastAPI app wrapper (not root)
â”‚   â”œâ”€â”€ crawl_urls.py          # Web crawler for Changi Airport URLs
â”‚   â”œâ”€â”€ embed_and_upload.py    # Embed documents and upload to Pinecone
â”‚   â”œâ”€â”€ rag_pipeline.py        # Core RAG pipeline
â”‚   â”œâ”€â”€ scrape_changi.py       # HTML scraper for airport content
â”‚   â”œâ”€â”€ utils.py               # Helper functions
â”‚   â””â”€â”€ vector_store.py        # Vector DB (Pinecone) handling
â”œâ”€â”€ chatui.py           # Streamlit-based chatbot UI
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ .env                       # Environment variables (not committed)
â”œâ”€â”€ README.md                  # Project documentation
```

---

## âš™ï¸ Technology Stack

* **FastAPI**: API backend
* **Streamlit**: Web UI
* **Sentence Transformers**: Embedding text
* **Pinecone**: Vector database for document retrieval
* **Hugging Face Inference API**: Text generation

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Shahul9570/airport-enquiry-bot.git
cd airport-enquiry-bot
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables

Create a `.env` file in the root with the following:

```
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX=your_index_name
HUGGINGFACE_TOKEN=your_huggingface_token
```

---

## ğŸ’¡ How It Works

1. User enters a question via Streamlit or API.
2. Question is embedded using SentenceTransformer.
3. Pinecone retrieves top matching documents.
4. Context and question are sent to HuggingFace model.
5. Final answer is returned.

---


## ğŸ“² Run Locally

### FastAPI

```bash
uvicorn app:app --reload
```

Visit: [http://localhost:8000](http://localhost:8000)

### Streamlit

```bash
streamlit run chatui.py
```

Visit: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“¢ Contact

For queries or collaboration, connect with [Muhammed Shahul](https://www.linkedin.com/in/muhammedshahul).
